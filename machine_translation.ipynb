{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "## Machine Translation Project\n",
    "In this notebook, sections that end with **'(IMPLEMENTATION)'** in the header indicate that the following blocks of code will require additional functionality which you must provide. Please be sure to read the instructions carefully!\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you will build a deep neural network that functions as part of an end-to-end machine translation pipeline. Your completed pipeline will accept English text as input and return the French translation.\n",
    "\n",
    "- **Preprocess** - You'll convert text to sequence of integers.\n",
    "- **Models** Create models which accepts a sequence of integers as input and returns a probability distribution over possible translations. After learning about the basic types of neural networks that are often used for machine translation, you will engage in your own investigations, to design your own model!\n",
    "- **Prediction** Run the model on English text.\n",
    "\n",
    "## Dataset\n",
    "We begin by investigating the dataset that will be used to train and evaluate your pipeline.  The most common datasets used for machine translation are from [WMT](http://www.statmt.org/).  However, that will take a long time to train a neural network on.  We'll be using a dataset we created for this project that contains a small vocabulary.  You'll be able to train your model in a reasonable time with this dataset.\n",
    "### Load Data\n",
    "The data is located in `data/small_vocab_en` and `data/small_vocab_fr`. The `small_vocab_en` file contains English sentences with their French translations in the `small_vocab_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "\n",
    "# Load English data\n",
    "english_sentences = helper.load_data('data/small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = helper.load_data('data/small_vocab_fr')\n",
    "\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "Each line in `small_vocab_en` contains an English sentence with the respective translation in each line of `small_vocab_fr`.  View the first two lines from each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 201:  paris is hot during spring , but it is usually snowy in june .\n",
      "small_vocab_fr Line 201:  paris est chaud au printemps , mais il est généralement enneigée en juin .\n",
      "small_vocab_en Line 202:  the grape is your least favorite fruit , but the banana is his least favorite .\n",
      "small_vocab_fr Line 202:  le raisin est votre fruit préféré moins , mais la banane est son moins préféré.\n",
      "small_vocab_en Line 203:  china is never warm during summer , but it is usually quiet in november .\n",
      "small_vocab_fr Line 203:  chine est jamais chaud pendant l' été , mais il est généralement calme en novembre .\n",
      "small_vocab_en Line 204:  she dislikes strawberries , pears , and limes .\n",
      "small_vocab_fr Line 204:  elle n'aime les fraises , les poires et citrons verts .\n",
      "small_vocab_en Line 205:  his least favorite animal is the mouse .\n",
      "small_vocab_fr Line 205:  son moins animal préféré est la souris .\n",
      "small_vocab_en Line 206:  he dislikes bananas , mangoes , and apples .\n",
      "small_vocab_fr Line 206:  il n'aime les bananes , les mangues et les pommes .\n",
      "small_vocab_en Line 207:  the lemon is our favorite fruit , but the orange is my favorite .\n",
      "small_vocab_fr Line 207:  le citron est notre fruit préféré , mais l'orange est mon préféré .\n",
      "small_vocab_en Line 208:  france is usually hot during spring , but it is never pleasant in september .\n",
      "small_vocab_fr Line 208:  la france est habituellement chaud au printemps , mais il est jamais agréable en septembre .\n",
      "small_vocab_en Line 209:  china is chilly during march , and it is never relaxing in may .\n",
      "small_vocab_fr Line 209:  chine est froid en mars , et il est jamais relaxant en mai .\n",
      "small_vocab_en Line 210:  france is sometimes mild during november , and it is sometimes busy in spring .\n",
      "small_vocab_fr Line 210:  la france est parfois doux en novembre , et il est parfois occupé au printemps .\n",
      "small_vocab_en Line 211:  california is usually mild during fall , but it is never chilly in september .\n",
      "small_vocab_fr Line 211:  californie est généralement doux à l'automne , mais il est jamais froid en septembre .\n",
      "small_vocab_en Line 212:  paris is never wonderful during september , and it is hot in july .\n",
      "small_vocab_fr Line 212:  paris est jamais merveilleux en septembre , et il est chaud en juillet .\n",
      "small_vocab_en Line 213:  we dislike peaches , limes , and oranges .\n",
      "small_vocab_fr Line 213:  nous détestons les pêches , citrons verts et oranges .\n",
      "small_vocab_en Line 214:  the apple is your least liked fruit , but the strawberry is their least liked .\n",
      "small_vocab_fr Line 214:  la pomme est votre fruit moins aimé , mais la fraise est leur moins aimé .\n",
      "small_vocab_en Line 215:  the united states is sometimes wonderful during autumn , but it is usually wet in june .\n",
      "small_vocab_fr Line 215:  les états-unis est parfois merveilleux au cours de l' automne , mais il est généralement humide en juin .\n",
      "small_vocab_en Line 216:  he went to the united states last spring .\n",
      "small_vocab_fr Line 216:  il est allé aux états-unis au printemps dernier .\n",
      "small_vocab_en Line 217:  france is wet during fall , and it is never relaxing in june .\n",
      "small_vocab_fr Line 217:  la france est humide à l'automne , et il est jamais relaxant en juin .\n",
      "small_vocab_en Line 218:  i like oranges , grapes , and pears .\n",
      "small_vocab_fr Line 218:  j'aime les oranges , les raisins et les poires .\n",
      "small_vocab_en Line 219:  he was driving the little yellow car .\n",
      "small_vocab_fr Line 219:  il conduisait la petite voiture jaune .\n",
      "small_vocab_en Line 220:  i dislike limes , apples , and peaches.\n",
      "small_vocab_fr Line 220:  je n'aime pas citrons verts , les pommes et les pêches .\n",
      "small_vocab_en Line 221:  the united states is snowy during march , but it is sometimes quiet in december .\n",
      "small_vocab_fr Line 221:  les états-unis est la neige en mars , mais il est parfois calme en décembre .\n",
      "small_vocab_en Line 222:  india is quiet during august , and it is usually mild in january .\n",
      "small_vocab_fr Line 222:  l' inde est calme au mois d' août , et il est généralement doux en janvier .\n",
      "small_vocab_en Line 223:  the united states is never freezing during november , but it is sometimes rainy in winter .\n",
      "small_vocab_fr Line 223:  les états-unis ne sont jamais glaciales en novembre , mais il est parfois pluvieux en hiver .\n",
      "small_vocab_en Line 224:  india is relaxing during fall , and it is wonderful in march .\n",
      "small_vocab_fr Line 224:  l' inde est relaxant à l'automne , et il est merveilleux en mars .\n",
      "small_vocab_en Line 225:  the strawberry is your favorite fruit , but the peach is our favorite.\n",
      "small_vocab_fr Line 225:  la fraise est votre fruit préféré , mais la pêche est notre préféré .\n",
      "small_vocab_en Line 226:  new jersey is sometimes rainy during fall , but it is freezing in spring .\n",
      "small_vocab_fr Line 226:  new jersey est parfois pluvieux au cours de l' automne , mais il gèle au printemps .\n",
      "small_vocab_en Line 227:  the banana is your least liked fruit , but the mango is my least liked .\n",
      "small_vocab_fr Line 227:  la banane est votre fruit moins aimé , mais la mangue est mon moins aimé .\n",
      "small_vocab_en Line 228:  france is usually pleasant during may , and it is never hot in winter .\n",
      "small_vocab_fr Line 228:  la france est généralement agréable au mois de mai , et il est jamais chaude en hiver .\n",
      "small_vocab_en Line 229:  the mango is our least liked fruit , but the banana is his least liked .\n",
      "small_vocab_fr Line 229:  la mangue est notre fruit moins aimé , mais la banane est le moins aimé .\n",
      "small_vocab_en Line 230:  india is usually warm during april , but it is usually busy in august .\n",
      "small_vocab_fr Line 230:  l' inde est habituellement chaud en avril , mais il est généralement occupé en août .\n",
      "small_vocab_en Line 231:  the orange is his favorite fruit , but the strawberry is our favorite .\n",
      "small_vocab_fr Line 231:  l'orange est son fruit préféré , mais la fraise est notre préféré .\n",
      "small_vocab_en Line 232:  you like grapes , limes , and mangoes .\n",
      "small_vocab_fr Line 232:  vous aimez raisins , citrons verts et les mangues .\n",
      "small_vocab_en Line 233:  that horse is your least favorite animal .\n",
      "small_vocab_fr Line 233:  ce cheval est votre animal préféré moins .\n",
      "small_vocab_en Line 234:  she dislikes bananas , oranges , and grapefruit .\n",
      "small_vocab_fr Line 234:  elle déteste les bananes , les oranges et le pamplemousse .\n",
      "small_vocab_en Line 235:  we dislike oranges , grapefruit , and bananas .\n",
      "small_vocab_fr Line 235:  nous détestons les oranges , le pamplemousse et les bananes .\n",
      "small_vocab_en Line 236:  paris is usually quiet during autumn , but it is usually snowy in march .\n",
      "small_vocab_fr Line 236:  paris est généralement calme au cours de l' automne , mais il est généralement enneigée en mars .\n",
      "small_vocab_en Line 237:  she likes apples , mangoes , and oranges .\n",
      "small_vocab_fr Line 237:  elle aime les pommes , les mangues et les oranges .\n",
      "small_vocab_en Line 238:  he dislikes the old red automobile .\n",
      "small_vocab_fr Line 238:  il n'aime la vieille voiture rouge .\n",
      "small_vocab_en Line 239:  dogs are your least favorite animals .\n",
      "small_vocab_fr Line 239:  les chiens sont vos animaux les moins préférés .\n",
      "small_vocab_en Line 240:  she was driving the little white car .\n",
      "small_vocab_fr Line 240:  elle conduisait la petite voiture blanche .\n",
      "small_vocab_en Line 241:  the united states is sometimes busy during spring , and it is usually mild in november .\n",
      "small_vocab_fr Line 241:  les états-unis est parfois occupée au printemps , et il est généralement doux en novembre .\n",
      "small_vocab_en Line 242:  california is sometimes freezing during september , and it is never warm in spring .\n",
      "small_vocab_fr Line 242:  la californie est parfois le gel en septembre , et il est jamais chaud au printemps .\n",
      "small_vocab_en Line 243:  china is snowy during august , but it is never beautiful in january .\n",
      "small_vocab_fr Line 243:  chine est neigeux au mois d' août , mais il est jamais beau en janvier .\n",
      "small_vocab_en Line 244:  our most loved fruit is the orange , but their most loved is the lemon .\n",
      "small_vocab_fr Line 244:  nos fruits le plus aimé est l'orange , mais leur plus aimé est le citron .\n",
      "small_vocab_en Line 245:  your least liked fruit is the grape , but his least liked is the orange .\n",
      "small_vocab_fr Line 245:  votre moins aimé fruit est le raisin , mais son moins aimé est l'orange .\n",
      "small_vocab_en Line 246:  india is sometimes quiet during december , but it is never nice in winter .\n",
      "small_vocab_fr Line 246:  l' inde est parfois calme en décembre , mais il est jamais agréable en hiver .\n",
      "small_vocab_en Line 247:  she dislikes oranges , grapes , and lemons .\n",
      "small_vocab_fr Line 247:  elle n'aime les oranges , les raisins et les citrons .\n",
      "small_vocab_en Line 248:  new jersey is never busy during november , and it is never cold in march .\n",
      "small_vocab_fr Line 248:  new jersey est jamais occupé en novembre , et il ne fait jamais froid en mars .\n",
      "small_vocab_en Line 249:  my least favorite fruit is the lime , but her least favorite is the pear .\n",
      "small_vocab_fr Line 249:  mon fruit préféré est moins la chaux , mais son moins préféré est la poire .\n",
      "small_vocab_en Line 250:  the grape is your least favorite fruit .\n",
      "small_vocab_fr Line 250:  le raisin est votre fruit préféré moins .\n",
      "small_vocab_en Line 251:  france is sometimes freezing during may , and it is never wet in august .\n",
      "small_vocab_fr Line 251:  la france est parfois le gel en mai , et il est jamais humide en août .\n",
      "small_vocab_en Line 252:  his favorite animals were horses .\n",
      "small_vocab_fr Line 252:  ses animaux étaient des chevaux préférés .\n",
      "small_vocab_en Line 253:  paris is never snowy during december , and it is never wet in february .\n",
      "small_vocab_fr Line 253:  paris est jamais de neige en décembre , et il est jamais humide en février .\n",
      "small_vocab_en Line 254:  india is sometimes pleasant during january , but it is never mild in october .\n",
      "small_vocab_fr Line 254:  l' inde est parfois agréable en janvier , mais il est jamais doux en octobre .\n",
      "small_vocab_en Line 255:  new jersey is cold during december , but it is never warm in february .\n",
      "small_vocab_fr Line 255:  new jersey est froid en décembre , mais il est jamais chaud en février .\n",
      "small_vocab_en Line 256:  the lime is our favorite fruit , but the lemon is her favorite.\n",
      "small_vocab_fr Line 256:  la chaux est notre fruit préféré , mais le citron est son favori .\n",
      "small_vocab_en Line 257:  he likes peaches , oranges , and lemons .\n",
      "small_vocab_fr Line 257:  il aime les pêches , les oranges , les citrons et les .\n",
      "small_vocab_en Line 258:  the united states is never warm during january , and it is rainy in september .\n",
      "small_vocab_fr Line 258:  les états-unis est jamais chaud en janvier , et il pleut en septembre .\n",
      "small_vocab_en Line 259:  the united states is pleasant during june , but it is sometimes warm in summer .\n",
      "small_vocab_fr Line 259:  les états-unis est agréable en juin , mais il est parfois chaud en été .\n",
      "small_vocab_en Line 260:  the grapefruit is their least liked fruit , but the mango is her least liked .\n",
      "small_vocab_fr Line 260:  le pamplemousse est leur fruit moins aimé , mais la mangue elle est moins aimé .\n",
      "small_vocab_en Line 261:  she is going to china next june .\n",
      "small_vocab_fr Line 261:  elle va en chine en juin prochain .\n",
      "small_vocab_en Line 262:  he likes strawberries , apples , and grapes .\n",
      "small_vocab_fr Line 262:  il aime les fraises , les pommes et les raisins .\n",
      "small_vocab_en Line 263:  china is sometimes busy during july , and it is usually quiet in march .\n",
      "small_vocab_fr Line 263:  la chine est parfois occupé en juillet , et il est généralement calme en mars .\n",
      "small_vocab_en Line 264:  we dislike bananas , lemons , and mangoes .\n",
      "small_vocab_fr Line 264:  nous détestons les bananes , les citrons et les mangues .\n",
      "small_vocab_en Line 265:  california is never busy during december , but it is usually hot in fall .\n",
      "small_vocab_fr Line 265:  california est jamais occupé en décembre , mais il est généralement chaud à l' automne .\n",
      "small_vocab_en Line 266:  france is usually relaxing during winter , but it is usually mild in july .\n",
      "small_vocab_fr Line 266:  la france est relaxant habituellement pendant l' hiver , mais il est généralement doux en juillet .\n",
      "small_vocab_en Line 267:  new jersey is usually hot during autumn , and it is never quiet in winter .\n",
      "small_vocab_fr Line 267:  new jersey est généralement chaud pendant l' automne , et il est jamais calme en hiver .\n",
      "small_vocab_en Line 268:  paris is never nice during september , and it is sometimes cold in march .\n",
      "small_vocab_fr Line 268:  paris est jamais agréable en septembre , et il est parfois froid en mars .\n",
      "small_vocab_en Line 269:  new jersey is sometimes wet during september , but it is usually beautiful in august .\n",
      "small_vocab_fr Line 269:  new jersey est parfois humide au mois de septembre , mais il est généralement beau en août .\n",
      "small_vocab_en Line 270:  the united states is sometimes rainy during march , and it is never hot in autumn .\n",
      "small_vocab_fr Line 270:  les états-unis est parfois pluvieux en mars , et il est jamais chaud à l' automne .\n",
      "small_vocab_en Line 271:  the elephant is his most loved animal .\n",
      "small_vocab_fr Line 271:  l'éléphant est son animal le plus aimé .\n",
      "small_vocab_en Line 272:  india is usually hot during october , and it is usually wet in june .\n",
      "small_vocab_fr Line 272:  l' inde est généralement chaud en octobre , et il est généralement humide en juin .\n",
      "small_vocab_en Line 273:  their least favorite fruit is the peach , but your least favorite is the banana .\n",
      "small_vocab_fr Line 273:  leur fruit préféré moins est la pêche , mais votre moins préféré est la banane .\n",
      "small_vocab_en Line 274:  paris is sometimes beautiful during september , but it is sometimes wet in march .\n",
      "small_vocab_fr Line 274:  paris est parfois belle en septembre , mais il est parfois humide en mars .\n",
      "small_vocab_en Line 275:  california is hot during october , and it is usually pleasant in march .\n",
      "small_vocab_fr Line 275:  californie est chaud en octobre , et il est généralement agréable en mars .\n",
      "small_vocab_en Line 276:  he likes grapes and lemons.\n",
      "small_vocab_fr Line 276:  il aime les raisins et les citrons .\n",
      "small_vocab_en Line 277:  new jersey is beautiful during march , but it is busy in winter .\n",
      "small_vocab_fr Line 277:  new jersey est belle en mars , mais il est occupé en hiver .\n",
      "small_vocab_en Line 278:  china is never wonderful during november , but it is sometimes quiet in spring .\n",
      "small_vocab_fr Line 278:  chine est jamais merveilleux au mois de novembre , mais il est parfois calme au printemps .\n",
      "small_vocab_en Line 279:  the united states is usually freezing during autumn , but it is usually dry in june .\n",
      "small_vocab_fr Line 279:  les états-unis est le gel habituellement pendant l' automne , mais il est généralement sec en juin .\n",
      "small_vocab_en Line 280:  the peach is my least favorite fruit , but the grape is their least favorite .\n",
      "small_vocab_fr Line 280:  la pêche est moins mon fruit préféré , mais le raisin est leur moins préféré .\n",
      "small_vocab_en Line 281:  he dislikes apples , limes , and pears .\n",
      "small_vocab_fr Line 281:  il déteste les pommes , les citrons verts , et les poires .\n",
      "small_vocab_en Line 282:  paris is usually cold during summer , and it is sometimes dry in winter .\n",
      "small_vocab_fr Line 282:  paris est généralement froid pendant l' été , et il est parfois sec en hiver .\n",
      "small_vocab_en Line 283:  paris is hot during may , and it is never pleasant in august .\n",
      "small_vocab_fr Line 283:  paris est chaud au mois de mai , et il est jamais agréable en août .\n",
      "small_vocab_en Line 284:  his favorite fruit is the grapefruit , but my favorite is the mango.\n",
      "small_vocab_fr Line 284:  son fruit préféré est le pamplemousse , mais mon préféré est la mangue .\n",
      "small_vocab_en Line 285:  the united states is sometimes pleasant during july , but it is sometimes dry in june .\n",
      "small_vocab_fr Line 285:  les états-unis est parfois agréable en juillet , mais il est parfois sec en juin .\n",
      "small_vocab_en Line 286:  the grape is our least liked fruit , but the strawberry is her least liked .\n",
      "small_vocab_fr Line 286:  le raisin est notre fruit moins aimé , mais la fraise elle est moins aimé.\n",
      "small_vocab_en Line 287:  california is never quiet during september , and it is sometimes mild in december .\n",
      "small_vocab_fr Line 287:  california est jamais calme en septembre , et il est parfois doux en décembre .\n",
      "small_vocab_en Line 288:  the lime is her least favorite fruit , but the peach is your least favorite .\n",
      "small_vocab_fr Line 288:  la chaux est son fruit préféré moins , mais la pêche est votre préféré moins .\n",
      "small_vocab_en Line 289:  the united states is never mild during august , but it is never beautiful in winter .\n",
      "small_vocab_fr Line 289:  les états-unis est jamais doux au mois d' août , mais il est beau jamais en hiver .\n",
      "small_vocab_en Line 290:  new jersey is never freezing during february , and it is usually cold in summer .\n",
      "small_vocab_fr Line 290:  new jersey est jamais le gel en février , et il est généralement froid en été .\n",
      "small_vocab_en Line 291:  the strawberry is their least liked fruit , but the apple is our least liked.\n",
      "small_vocab_fr Line 291:  la fraise est leur fruit moins aimé , mais la pomme est notre moins aimé .\n",
      "small_vocab_en Line 292:  india is never beautiful during spring , but it is usually freezing in february .\n",
      "small_vocab_fr Line 292:  l' inde est jamais belle au printemps , mais il gèle habituellement en février .\n",
      "small_vocab_en Line 293:  the grape is our least liked fruit , but the grapefruit is his least liked .\n",
      "small_vocab_fr Line 293:  le raisin est notre fruit moins aimé , mais le pamplemousse est son moins aimé.\n",
      "small_vocab_en Line 294:  i plan to visit france in spring .\n",
      "small_vocab_fr Line 294:  je prévois de visiter la france au printemps .\n",
      "small_vocab_en Line 295:  new jersey is never nice during february , but it is chilly in spring .\n",
      "small_vocab_fr Line 295:  new jersey est jamais agréable en février , mais il est froid au printemps .\n",
      "small_vocab_en Line 296:  she saw that new yellow truck .\n",
      "small_vocab_fr Line 296:  elle a vu ce nouveau camion jaune .\n",
      "small_vocab_en Line 297:  she likes grapes , apples , and grapefruit.\n",
      "small_vocab_fr Line 297:  elle aime les raisins , les pommes et le pamplemousse .\n",
      "small_vocab_en Line 298:  that cat was your favorite animal .\n",
      "small_vocab_fr Line 298:  ce chat était votre animal préféré .\n",
      "small_vocab_en Line 299:  the united states is sometimes snowy during march , and it is usually cold in october .\n",
      "small_vocab_fr Line 299:  les états-unis est parfois enneigée en mars , et il est généralement froid en octobre .\n",
      "small_vocab_en Line 300:  the united states is sometimes beautiful during april , but it is usually busy in october .\n",
      "small_vocab_fr Line 300:  les états-unis est parfois belle en avril , mais il est généralement occupé en octobre .\n",
      "small_vocab_en Line 301:  california is beautiful during september , but it is wonderful in august .\n",
      "small_vocab_fr Line 301:  californie est beau au mois de septembre , mais il est merveilleux en août .\n",
      "small_vocab_en Line 302:  her most loved fruit is the apple , but their most loved is the grape .\n",
      "small_vocab_fr Line 302:  son fruit le plus aimé est la pomme , mais leur plus aimé est le raisin .\n",
      "small_vocab_en Line 303:  he likes grapes and apples.\n",
      "small_vocab_fr Line 303:  il aime les raisins et les pommes .\n",
      "small_vocab_en Line 304:  california is chilly during january , but it is never busy in spring .\n",
      "small_vocab_fr Line 304:  california est froid en janvier , mais il est jamais occupé au printemps .\n",
      "small_vocab_en Line 305:  she dislikes bananas , grapefruit , and mangoes .\n",
      "small_vocab_fr Line 305:  elle déteste les bananes , le pamplemousse et les mangues .\n",
      "small_vocab_en Line 306:  you dislike bananas , peaches , and limes .\n",
      "small_vocab_fr Line 306:  vous n'aimez pas les bananes , les pêches et les citrons verts .\n",
      "small_vocab_en Line 307:  california is never warm during march , but it is sometimes relaxing in may .\n",
      "small_vocab_fr Line 307:  california est jamais chaud au mois de mars , mais il est parfois relaxant en mai .\n",
      "small_vocab_en Line 308:  paris is mild during december , but it is dry in winter .\n",
      "small_vocab_fr Line 308:  paris est doux en décembre , mais il est sec en hiver .\n",
      "small_vocab_en Line 309:  our most loved fruit is the grapefruit , but their most loved is the pear .\n",
      "small_vocab_fr Line 309:  nos fruits le plus aimé est le pamplemousse , mais leur plus aimé est la poire .\n",
      "small_vocab_en Line 310:  france is sometimes chilly during june , but it is sometimes wet in november .\n",
      "small_vocab_fr Line 310:  la france est parfois froid en juin , mais il est parfois humide en novembre .\n",
      "small_vocab_en Line 311:  paris is sometimes quiet during may , but it is usually dry in january .\n",
      "small_vocab_fr Line 311:  paris est parfois calme au mois de mai , mais il est généralement sec en janvier .\n",
      "small_vocab_en Line 312:  our most loved fruit is the strawberry , but his most loved is the mango.\n",
      "small_vocab_fr Line 312:  nos fruits le plus aimé est la fraise , mais son plus aimé est la mangue .\n",
      "small_vocab_en Line 313:  our least liked fruit is the grape , but her least liked is the grapefruit .\n",
      "small_vocab_fr Line 313:  notre moins aimé fruit est le raisin , mais son moins aimé est le pamplemousse .\n",
      "small_vocab_en Line 314:  their favorite fruit is the apple , but his favorite is the strawberry .\n",
      "small_vocab_fr Line 314:  leur fruit préféré est la pomme , mais son favori est la fraise .\n",
      "small_vocab_en Line 315:  my least liked fruit is the pear , but her least liked is the mango .\n",
      "small_vocab_fr Line 315:  mon fruit est moins aimé la poire , mais elle est moins aimé la mangue .\n",
      "small_vocab_en Line 316:  we like peaches , grapes , and apples .\n",
      "small_vocab_fr Line 316:  nous aimons les pêches , les raisins et les pommes .\n",
      "small_vocab_en Line 317:  france is never wet during september , but it is usually mild in december .\n",
      "small_vocab_fr Line 317:  la france est jamais humide en septembre , mais il est généralement doux en décembre .\n",
      "small_vocab_en Line 318:  the lemon is your least liked fruit , but the peach is his least liked .\n",
      "small_vocab_fr Line 318:  le citron est votre fruit moins aimé , mais la pêche est son moins aimé .\n",
      "small_vocab_en Line 319:  new jersey is cold during february , and it is never hot in winter .\n",
      "small_vocab_fr Line 319:  new jersey est froid en février , et il est jamais chaude en hiver .\n",
      "small_vocab_en Line 320:  the united states is never freezing during november , but it is sometimes cold in fall .\n",
      "small_vocab_fr Line 320:  les états-unis ne sont jamais glaciales en novembre , mais il est parfois froid à l' automne .\n",
      "small_vocab_en Line 321:  france is usually quiet during august , but it is usually chilly in february .\n",
      "small_vocab_fr Line 321:  la france est généralement calme au mois d' août , mais il est généralement froid en février .\n",
      "small_vocab_en Line 322:  california is pleasant during january , but it is usually chilly in april .\n",
      "small_vocab_fr Line 322:  californie est agréable en janvier , mais il est généralement froid en avril .\n",
      "small_vocab_en Line 323:  they like grapes , peaches , and strawberries .\n",
      "small_vocab_fr Line 323:  ils aiment les raisins , les pêches et les fraises .\n",
      "small_vocab_en Line 324:  china is never wonderful during april , but it is sometimes wet in march .\n",
      "small_vocab_fr Line 324:  chine est jamais merveilleux en avril , mais il est parfois humide en mars .\n",
      "small_vocab_en Line 325:  i dislike peaches , mangoes , and oranges .\n",
      "small_vocab_fr Line 325:  je n'aime pas les pêches , les mangues et les oranges .\n",
      "small_vocab_en Line 326:  your favorite fruit is the strawberry , but our favorite is the banana.\n",
      "small_vocab_fr Line 326:  votre fruit préféré est la fraise , mais notre préféré est la banane .\n",
      "small_vocab_en Line 327:  she likes bananas , strawberries , and grapes .\n",
      "small_vocab_fr Line 327:  elle aime les bananes , les fraises et les raisins .\n",
      "small_vocab_en Line 328:  his least favorite fruit is the grapefruit , but our least favorite is the peach.\n",
      "small_vocab_fr Line 328:  son fruit préféré moins est le pamplemousse , mais notre moins préféré est la pêche .\n",
      "small_vocab_en Line 329:  india is nice during december , but it is sometimes warm in january .\n",
      "small_vocab_fr Line 329:  l' inde est agréable en décembre , mais il est parfois chaud en janvier .\n",
      "small_vocab_en Line 330:  the orange is their least favorite fruit , but the lime is his least favorite .\n",
      "small_vocab_fr Line 330:  l'orange est leur fruit préféré moins , mais la chaux est son moins préféré .\n",
      "small_vocab_en Line 331:  the mango is their most loved fruit , but the pear is my most loved .\n",
      "small_vocab_fr Line 331:  la mangue est leur fruit le plus cher , mais la poire est mon plus aimé .\n",
      "small_vocab_en Line 332:  india is never wet during august , but it is sometimes hot in winter .\n",
      "small_vocab_fr Line 332:  l' inde est jamais humide au mois d' août , mais il est parfois chaud en hiver .\n",
      "small_vocab_en Line 333:  new jersey is sometimes hot during winter , and it is never nice in fall .\n",
      "small_vocab_fr Line 333:  new jersey est parfois chaud pendant l' hiver , et il est jamais agréable à l' automne .\n",
      "small_vocab_en Line 334:  he is driving the old black car .\n",
      "small_vocab_fr Line 334:  il conduit la vieille voiture noire .\n",
      "small_vocab_en Line 335:  paris is never cold during january , but it is sometimes snowy in november .\n",
      "small_vocab_fr Line 335:  paris ne fait jamais froid en janvier , mais il est parfois enneigée en novembre .\n",
      "small_vocab_en Line 336:  the grape is my favorite fruit , but the peach is his favorite.\n",
      "small_vocab_fr Line 336:  le raisin est mon fruit préféré , mais la pêche est son favori .\n",
      "small_vocab_en Line 337:  france is snowy during july , but it is beautiful in june .\n",
      "small_vocab_fr Line 337:  la france est la neige en juillet , mais il est beau en juin .\n",
      "small_vocab_en Line 338:  paris is never busy during february , and it is never cold in august .\n",
      "small_vocab_fr Line 338:  paris est jamais occupé en février , et il ne fait jamais froid en août .\n",
      "small_vocab_en Line 339:  california is sometimes relaxing during april , but it is sometimes dry in autumn .\n",
      "small_vocab_fr Line 339:  california est relaxant parfois en avril , mais il est parfois sec à l' automne .\n",
      "small_vocab_en Line 340:  india is relaxing during february , but it is never rainy in june .\n",
      "small_vocab_fr Line 340:  l' inde est relaxant en février , mais jamais des pluies en juin .\n",
      "small_vocab_en Line 341:  california is usually chilly during may , and it is sometimes dry in july .\n",
      "small_vocab_fr Line 341:  californie est généralement froid au mois de mai , et il est parfois sec en juillet .\n",
      "small_vocab_en Line 342:  china is never busy during september , but it is rainy in october .\n",
      "small_vocab_fr Line 342:  chine est jamais occupée en septembre , mais il est pluvieux en octobre .\n",
      "small_vocab_en Line 343:  new jersey is busy during august , and it is relaxing in december .\n",
      "small_vocab_fr Line 343:  new jersey est occupé au mois d' août , et il est relaxant en décembre .\n",
      "small_vocab_en Line 344:  i think it is difficult to translate between spanish and portuguese .\n",
      "small_vocab_fr Line 344:  je pense qu'il est difficile de traduire entre l' espagnol et le portugais .\n",
      "small_vocab_en Line 345:  india is busy during april , but it is sometimes dry in fall .\n",
      "small_vocab_fr Line 345:  l' inde est occupé en avril , mais il est parfois sec à l' automne .\n",
      "small_vocab_en Line 346:  france is busy during august , and it is nice in february .\n",
      "small_vocab_fr Line 346:  france est occupé au mois d' août , et il est agréable en février .\n",
      "small_vocab_en Line 347:  their favorite fruit is the orange , but my favorite is the grapefruit .\n",
      "small_vocab_fr Line 347:  leur fruit préféré est l'orange , mais mon préféré est le pamplemousse .\n",
      "small_vocab_en Line 348:  paris is sometimes rainy during winter , but it is chilly in fall .\n",
      "small_vocab_fr Line 348:  paris est parfois pluvieux pendant l' hiver , mais il est froid à l' automne .\n",
      "small_vocab_en Line 349:  india is usually beautiful during july , but it is cold in autumn .\n",
      "small_vocab_fr Line 349:  l' inde est généralement beau en juillet , mais il est froid à l' automne .\n",
      "small_vocab_en Line 350:  the pear is your least liked fruit , but the lemon is my least liked .\n",
      "small_vocab_fr Line 350:  la poire est votre fruit moins aimé , mais le citron est mon moins aimé .\n",
      "small_vocab_en Line 351:  her least favorite fruit is the banana , but your least favorite is the grapefruit .\n",
      "small_vocab_fr Line 351:  son fruit préféré moins est la banane , mais votre moins préféré est le pamplemousse .\n",
      "small_vocab_en Line 352:  france is sometimes quiet during november , but it is warm in february .\n",
      "small_vocab_fr Line 352:  la france est parfois calme au mois de novembre , mais il est chaud en février .\n",
      "small_vocab_en Line 353:  new jersey is rainy during summer , but it is sometimes mild in february .\n",
      "small_vocab_fr Line 353:  new jersey est pluvieux pendant l' été , mais il est parfois doux en février .\n",
      "small_vocab_en Line 354:  new jersey is never rainy during autumn , but it is never pleasant in march .\n",
      "small_vocab_fr Line 354:  new jersey est jamais pluvieux au cours de l' automne , mais il est jamais agréable en mars .\n",
      "small_vocab_en Line 355:  france is never snowy during october , and it is sometimes wet in april .\n",
      "small_vocab_fr Line 355:  la france est jamais de neige en octobre , et il est parfois humide en avril .\n",
      "small_vocab_en Line 356:  the lime is her least liked fruit , but the grape is our least liked .\n",
      "small_vocab_fr Line 356:  la chaux est son fruit moins aimé , mais le raisin est notre moins aimé.\n",
      "small_vocab_en Line 357:  she is driving the rusty blue truck .\n",
      "small_vocab_fr Line 357:  elle conduit le camion bleu rouillé .\n",
      "small_vocab_en Line 358:  paris is usually beautiful during july , and it is sometimes chilly in may .\n",
      "small_vocab_fr Line 358:  paris est généralement beau en juillet , et il est parfois frisquet en mai .\n",
      "small_vocab_en Line 359:  france is never busy during autumn , but it is quiet in january .\n",
      "small_vocab_fr Line 359:  la france est jamais occupé à l'automne , mais il est calme en janvier .\n",
      "small_vocab_en Line 360:  india is never quiet during january , but it is sometimes freezing in december .\n",
      "small_vocab_fr Line 360:  l' inde est jamais tranquille en janvier , mais il est parfois le gel en décembre .\n",
      "small_vocab_en Line 361:  new jersey is sometimes wet during october , but it is mild in summer .\n",
      "small_vocab_fr Line 361:  new jersey est parfois humide en octobre , mais il est doux en été .\n",
      "small_vocab_en Line 362:  china is never chilly during february , and it is sometimes wonderful in november .\n",
      "small_vocab_fr Line 362:  chine est jamais froid en février , et il est parfois merveilleux en novembre .\n",
      "small_vocab_en Line 363:  the united states is quiet during fall , but it is usually freezing in may .\n",
      "small_vocab_fr Line 363:  les états-unis est calme à l'automne , mais il gèle habituellement en mai .\n",
      "small_vocab_en Line 364:  california is never busy during fall , but it is sometimes wet in april .\n",
      "small_vocab_fr Line 364:  california est jamais occupé à l'automne , mais il est parfois humide en avril .\n",
      "small_vocab_en Line 365:  they dislike pears , grapes , and bananas .\n",
      "small_vocab_fr Line 365:  ils n'aiment les poires , les raisins et les bananes .\n",
      "small_vocab_en Line 366:  he liked a big green automobile .\n",
      "small_vocab_fr Line 366:  il aimait une grande voiture verte .\n",
      "small_vocab_en Line 367:  new jersey is sometimes quiet during winter , and it is never hot in spring .\n",
      "small_vocab_fr Line 367:  new jersey est parfois calme pendant l' hiver , et il est jamais chaud au printemps .\n",
      "small_vocab_en Line 368:  new jersey is sometimes beautiful during march , but it is usually wonderful in summer .\n",
      "small_vocab_fr Line 368:  new jersey est parfois belle en mars , mais il est généralement merveilleux en été .\n",
      "small_vocab_en Line 369:  they dislike mangoes , grapes , and strawberries.\n",
      "small_vocab_fr Line 369:  ils n'aiment les mangues , les raisins et les fraises .\n",
      "small_vocab_en Line 370:  the united states is never beautiful during november , and it is never quiet in july .\n",
      "small_vocab_fr Line 370:  les états-unis est jamais belle au mois de novembre , et il est jamais tranquille en juillet .\n",
      "small_vocab_en Line 371:  i think translating between spanish and portuguese is fun .\n",
      "small_vocab_fr Line 371:  je pense que la traduction entre l' espagnol et le portugais est amusant .\n",
      "small_vocab_en Line 372:  the banana is our favorite fruit , but the lemon is your favorite .\n",
      "small_vocab_fr Line 372:  la banane est notre fruit préféré , mais le citron est votre favori .\n",
      "small_vocab_en Line 373:  paris is sometimes snowy during january , and it is usually hot in april .\n",
      "small_vocab_fr Line 373:  paris est parfois enneigée en janvier , et il est généralement chaud en avril .\n",
      "small_vocab_en Line 374:  their least favorite fruit is the mango , but her least favorite is the peach .\n",
      "small_vocab_fr Line 374:  leur fruit préféré est moins la mangue , mais son moins préféré est la pêche .\n",
      "small_vocab_en Line 375:  new jersey is never cold during september , and it is sometimes quiet in july .\n",
      "small_vocab_fr Line 375:  new jersey ne fait jamais froid en septembre , et il est parfois calme en juillet .\n",
      "small_vocab_en Line 376:  china is usually wonderful during october , and it is usually dry in june .\n",
      "small_vocab_fr Line 376:  chine est généralement merveilleux en octobre , et il est généralement sec en juin .\n",
      "small_vocab_en Line 377:  she saw that rusty white car .\n",
      "small_vocab_fr Line 377:  elle a vu cette voiture blanche rouillée .\n",
      "small_vocab_en Line 378:  france is wonderful during december , but it is sometimes freezing in winter .\n",
      "small_vocab_fr Line 378:  france est merveilleux en décembre , mais il est parfois le gel en hiver .\n",
      "small_vocab_en Line 379:  the united states is relaxing during november , and it is sometimes snowy in winter .\n",
      "small_vocab_fr Line 379:  les états-unis est relaxant au mois de novembre , et il est parfois enneigée en hiver .\n",
      "small_vocab_en Line 380:  your least favorite fruit is the banana , but our least favorite is the strawberry .\n",
      "small_vocab_fr Line 380:  votre fruit préféré moins est la banane , mais notre moins préféré est la fraise .\n",
      "small_vocab_en Line 381:  she saw the new green truck .\n",
      "small_vocab_fr Line 381:  elle a vu le nouveau camion vert .\n",
      "small_vocab_en Line 382:  the strawberry is your most loved fruit , but the lemon is his most loved.\n",
      "small_vocab_fr Line 382:  la fraise est votre fruit le plus aimé , mais le citron est le plus aimé .\n",
      "small_vocab_en Line 383:  new jersey is never busy during october , but it is cold in september .\n",
      "small_vocab_fr Line 383:  new jersey est jamais occupé en octobre , mais il est froid en septembre .\n",
      "small_vocab_en Line 384:  they like mangoes , limes , and grapes.\n",
      "small_vocab_fr Line 384:  ils aiment les mangues , les citrons verts , et les raisins .\n",
      "small_vocab_en Line 385:  the pear is her least liked fruit , but the orange is their least liked .\n",
      "small_vocab_fr Line 385:  la poire est la moins aimé des fruits , mais l'orange est leur moins aimé .\n",
      "small_vocab_en Line 386:  china is usually freezing during february , but it is never snowy in summer .\n",
      "small_vocab_fr Line 386:  la chine est le gel habituellement en février , mais jamais de neige en été .\n",
      "small_vocab_en Line 387:  your most loved fruit is the peach , but my most loved is the mango .\n",
      "small_vocab_fr Line 387:  votre fruit le plus aimé est la pêche , mais mon plus aimé est la mangue .\n",
      "small_vocab_en Line 388:  he likes that big blue truck .\n",
      "small_vocab_fr Line 388:  il aime ce grand camion bleu .\n",
      "small_vocab_en Line 389:  new jersey is sometimes relaxing during february , but it is never wet in october .\n",
      "small_vocab_fr Line 389:  new jersey est relaxant parfois en février , mais il est jamais humide en octobre .\n",
      "small_vocab_en Line 390:  new jersey is snowy during march , but it is sometimes wonderful in november .\n",
      "small_vocab_fr Line 390:  new jersey est la neige en mars , mais il est parfois merveilleux en novembre .\n",
      "small_vocab_en Line 391:  india is usually quiet during june , but it is never snowy in december .\n",
      "small_vocab_fr Line 391:  l' inde est généralement calme en juin , mais jamais de neige en décembre .\n",
      "small_vocab_en Line 392:  the united states is cold during july , but it is sometimes rainy in may .\n",
      "small_vocab_fr Line 392:  les états-unis est froid en juillet , mais il est parfois pluvieux en mai .\n",
      "small_vocab_en Line 393:  she is driving the little white truck .\n",
      "small_vocab_fr Line 393:  elle conduit le petit camion blanc .\n",
      "small_vocab_en Line 394:  my most loved animal was that bird .\n",
      "small_vocab_fr Line 394:  mon animal le plus aimé était cet oiseau .\n",
      "small_vocab_en Line 395:  my least liked fruit is the grapefruit , but our least liked is the orange .\n",
      "small_vocab_fr Line 395:  mon moins aimé est le fruit de pamplemousse , mais notre moins aimé est l'orange .\n",
      "small_vocab_en Line 396:  paris is busy during may , and it is usually rainy in november .\n",
      "small_vocab_fr Line 396:  paris est occupé au mois de mai , et il est généralement pluvieux en novembre .\n",
      "small_vocab_en Line 397:  the grape is my favorite fruit , but the lime is our favorite.\n",
      "small_vocab_fr Line 397:  le raisin est mon fruit préféré , mais la chaux est notre préféré .\n",
      "small_vocab_en Line 398:  paris is dry during march , and it is never quiet in august .\n",
      "small_vocab_fr Line 398:  paris est sec en mars , et il est jamais tranquille en août .\n",
      "small_vocab_en Line 399:  china is relaxing during january , but it is sometimes beautiful in spring .\n",
      "small_vocab_fr Line 399:  chine est relaxant en janvier , mais il est parfois beau au printemps .\n",
      "small_vocab_en Line 400:  india is pleasant during winter , but it is usually quiet in july .\n",
      "small_vocab_fr Line 400:  l' inde est agréable en hiver , mais il est généralement calme en juillet .\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(200,400):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the sentences, you can see they have been preprocessed already.  The puncuations have been delimited using spaces. All the text have been converted to lowercase.  This should save you some time, but the text requires more preprocessing.\n",
    "### Vocabulary\n",
    "The complexity of the problem is determined by the complexity of the vocabulary.  A more complex vocabulary is a more complex problem.  Let's look at the complexity of the dataset we'll be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, _Alice's Adventures in Wonderland_ contains 2,766 unique words of a total of 15,500 words.\n",
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Tokenize the words into ids\n",
    "2. Add padding to make all the sequences the same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize (IMPLEMENTATION)\n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "Running the cell will run `tokenize` on sample data and show output for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 3, 'short': 20, 'lazy': 8, 'fox': 5, 'the': 1, 'by': 10, 'dog': 9, 'won': 16, 'jove': 11, 'sentence': 21, 'of': 14, 'is': 19, 'prize': 17, 'over': 7, 'lexicography': 15, 'quick': 2, 'brown': 4, 'jumps': 6, 'study': 13, 'this': 18, 'my': 12}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import project_tests as tests\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    tok=keras.preprocessing.text.Tokenizer()\n",
    "    tok.fit_on_texts(x)\n",
    "    toks=tok.texts_to_sequences(x)\n",
    "    return toks, tok\n",
    "tests.test_tokenize(tokenize)\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding (IMPLEMENTATION)\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length.  Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the **end** of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    \n",
    "    return pad_sequences(x, length,padding='post',truncating='post')\n",
    "tests.test_pad(pad)\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Pipeline\n",
    "Your focus for this project is to build neural network architecture, so we won't ask you to create a preprocess pipeline.  Instead, we've provided you with the implementation of the `preprocess` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "In this section, you will experiment with various neural network architectures.\n",
    "You will begin by training four relatively simple architectures.\n",
    "- Model 1 is a simple RNN\n",
    "- Model 2 is a RNN with Embedding\n",
    "- Model 3 is a Bidirectional RNN\n",
    "- Model 4 is an optional Encoder-Decoder RNN\n",
    "\n",
    "After experimenting with the four simple architectures, you will construct a deeper architecture that is designed to outperform all four models.\n",
    "### Ids Back to Text\n",
    "The neural network will be translating the input to words ids, which isn't the final form we want.  We want the French translation.  The function `logits_to_text` will bridge the gab between the logits from the neural network to the French translation.  You'll be using this function to better understand the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def ids_to_text(ids, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn ids from the rakenizer back into text using the tokenizer\n",
    "    :param ids : words ids that has been tokenized\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the ids\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: RNN (IMPLEMENTATION)\n",
    "![RNN](images/rnn.png)\n",
    "A basic RNN model is a good baseline for sequence data.  In this model, you'll build a RNN that translates English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape ,  *input_shape[1:]: \n",
      "(137861, 21, 1) 21 1\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n",
      "YO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, return_sequences=True, input_shape=(21, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YO\n",
      "YA\n",
      "YO\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_39 (GRU)                 (None, 21, 128)           49920     \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 94,296\n",
      "Trainable params: 94,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Input shape ,  *input_shape[1:]: \n",
      "(137861, 21, 1) 21 1\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n",
      "YO\n",
      "YO\n",
      "YA\n",
      "YO\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_40 (GRU)                 (None, 21, 128)           49920     \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 94,296\n",
      "Trainable params: 94,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 44s - loss: 1.8951 - acc: 0.5569 - val_loss: nan - val_acc: 0.6377\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 31s - loss: 1.2321 - acc: 0.6472 - val_loss: nan - val_acc: 0.6592\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 32s - loss: 1.1077 - acc: 0.6627 - val_loss: nan - val_acc: 0.6711\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 32s - loss: 1.0454 - acc: 0.6720 - val_loss: nan - val_acc: 0.6735\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 31s - loss: 1.0006 - acc: 0.6840 - val_loss: nan - val_acc: 0.6807\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 31s - loss: 0.9566 - acc: 0.6978 - val_loss: nan - val_acc: 0.7088\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 31s - loss: 0.9200 - acc: 0.7093 - val_loss: nan - val_acc: 0.7170\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.8805 - acc: 0.7208 - val_loss: nan - val_acc: 0.7237\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.8541 - acc: 0.7277 - val_loss: nan - val_acc: 0.7113\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.8804 - acc: 0.7108 - val_loss: nan - val_acc: 0.7208\n",
      "new jersey est parfois calme en mois de il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU, Input, Dense, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "\n",
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a basic RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    \n",
    "    print(\"Input shape : {}\".format(input_shape))\n",
    "    print(\"english_vocab_size : {}\".format(english_vocab_size))\n",
    "    print(\"output_sequence_length : {}\".format(output_sequence_length))\n",
    "    \n",
    "    model.add(GRU(units=128,input_dim=1, input_length=output_sequence_length,return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate=0.01\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "tests.test_simple_model(simple_model)\n",
    "\n",
    "\n",
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index),\n",
    "    len(french_tokenizer.word_index))\n",
    "simple_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21, 1)\n",
      "(1, 21, 1)\n",
      "new jersey is sometimes quiet during autumn and it is snowy in april <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme en mois de il est est en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is usually chilly during july and it is usually freezing in november <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est généralement froid en juillet et il est généralement agréable en novembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "california is usually quiet during march and it is usually hot in june <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "californie est généralement chaud en l' et il est généralement chaud en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is sometimes mild during june and it is cold in september <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est parfois doux en printemps et il est froid en septembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "your least liked fruit is the grape but my least liked is the apple <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "elle fruit est moins aimé la raisin mais mon moins aimé est la <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "his favorite fruit is the orange but my favorite is the grape <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "son fruit préféré est la citron mais votre préféré est la raisin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "paris is relaxing during december but it is usually chilly in july <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "paris inde est au décembre mais mais est est généralement en en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey is busy during spring and it is never hot in march <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est froid au printemps et il est jamais chaud en hiver <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "our least liked fruit is the lemon but my least liked is the grape <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "leurs fruit moins aimé est la la mais mon moins aimé est la raisin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is sometimes busy during january and it is sometimes warm in november <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est parfois froid en janvier et il est parfois chaud en novembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the lime is her least liked fruit but the banana is my least liked <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les poire est son fruit aimé des fruits mais la est est moins moins <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "he saw a old yellow truck <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "elle a conduit une voiture voiture <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "# Print  more prediction(s)\n",
    "\n",
    "for i in range(12):\n",
    "#print(simple_rnn_model.predict(tmp_x[:1])[0].shape)\n",
    "#print((tmp_x[0,:,0]).shape)\n",
    "    print(ids_to_text(tmp_x[i,:,0],english_tokenizer))\n",
    "    print(logits_to_text(simple_rnn_model.predict(tmp_x[i:i+1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Embedding (IMPLEMENTATION)\n",
    "![RNN](images/embedding.png)\n",
    "You've turned the words into ids, but there's a better representation of a word.  This is called word embeddings.  An embedding is a vector representation of the word that is close to similar words in n-dimensional space, where the n represents the size of the embedding vectors.\n",
    "\n",
    "In this model, you'll create a RNN model using embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (137861, 21)\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, return_sequences=True, input_shape=(21, 64))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 21, 64)            12736     \n",
      "_________________________________________________________________\n",
      "gru_45 (GRU)                 (None, 21, 128)           74112     \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 131,224\n",
      "Trainable params: 131,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Input shape : (137861, 21)\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 21, 64)            12736     \n",
      "_________________________________________________________________\n",
      "gru_46 (GRU)                 (None, 21, 128)           74112     \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 21, 344)           44376     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 131,224\n",
      "Trainable params: 131,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 37s - loss: 1.8619 - acc: 0.6047 - val_loss: nan - val_acc: 0.7916\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.5253 - acc: 0.8402 - val_loss: nan - val_acc: 0.8798\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.3354 - acc: 0.8944 - val_loss: nan - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.2724 - acc: 0.9123 - val_loss: nan - val_acc: 0.9171\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.2441 - acc: 0.9204 - val_loss: nan - val_acc: 0.9201\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 32s - loss: 0.2281 - acc: 0.9244 - val_loss: nan - val_acc: 0.9244\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 33s - loss: 0.2151 - acc: 0.9278 - val_loss: nan - val_acc: 0.9271\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 33s - loss: 0.2095 - acc: 0.9290 - val_loss: nan - val_acc: 0.9234\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 33s - loss: 0.2067 - acc: 0.9296 - val_loss: nan - val_acc: 0.9289\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 33s - loss: 0.1977 - acc: 0.9319 - val_loss: nan - val_acc: 0.9298\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-a3943633e8f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#print(simple_rnn_model.predict(tmp_x[:1])[0].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#print((tmp_x[0,:,0]).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menglish_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_rnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "\n",
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a RNN model using word embedding on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 64, input_length=output_sequence_length))\n",
    "    \n",
    "    print(\"Input shape : {}\".format(input_shape))\n",
    "    print(\"english_vocab_size : {}\".format(english_vocab_size))\n",
    "    print(\"output_sequence_length : {}\".format(output_sequence_length))\n",
    "    \n",
    "    model.add(GRU(units=128,input_dim=64, input_length=output_sequence_length,return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate=0.01\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "tests.test_embed_model(embed_model)\n",
    "\n",
    "\n",
    "# TODO: Reshape the input\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "#tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "# TODO: Train the neural network\n",
    "embed_rnn_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index),\n",
    "    len(french_tokenizer.word_index))\n",
    "embed_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# TODO: Print prediction(s)\n",
    "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))\n",
    "\n",
    "# Print  more prediction(s)\n",
    "\n",
    "for i in range(12):\n",
    "#print(simple_rnn_model.predict(tmp_x[:1])[0].shape)\n",
    "#print((tmp_x[0,:,0]).shape)\n",
    "    print(ids_to_text(tmp_x[i,:,0],english_tokenizer))\n",
    "    print(logits_to_text(embed_rnn_model.predict(tmp_x[i:i+1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new jersey is sometimes quiet during autumn and it is snowy in april <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est parfois calme en l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is usually chilly during july and it is usually freezing in november <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est généralement froid en juillet et il est généralement en juillet <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "california is usually quiet during march and it is usually hot in june <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "californie est généralement calme en mars et il est généralement chaud en juin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is sometimes mild during june and it is cold in september <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est parfois doux en juin et il est froid en septembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "your least liked fruit is the grape but my least liked is the apple <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "votre fruit aimé fruit est la raisin mais mon moins aimé est la pomme <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "his favorite fruit is the orange but my favorite is the grape <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "son fruit préféré est la mais leur préféré est la poire <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "paris is relaxing during december but it is usually chilly in july <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "paris est relaxant au décembre mais il est généralement froid en juillet <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey is busy during spring and it is never hot in march <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "new jersey est occupé en printemps et il est jamais chaud en mars <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "our least liked fruit is the lemon but my least liked is the grape <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "notre moins aimé fruit est la citron mais mon moins aimé est la raisin <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the united states is sometimes busy during january and it is sometimes warm in november <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les états unis est parfois occupée en janvier et il est parfois chaud en novembre <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "the lime is her least liked fruit but the banana is my least liked <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "les chaux est son fruit aimé des fruits mais la banane est mon moins aimé <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "he saw a old yellow truck <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "il a vu un vieille camion jaune <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "#print(simple_rnn_model.predict(tmp_x[:1])[0].shape)\n",
    "#print((tmp_x[0,:,0]).shape)\n",
    "    print(ids_to_text(tmp_x[i,:],english_tokenizer))\n",
    "    print(logits_to_text(embed_rnn_model.predict(tmp_x[i:i+1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bidirectional RNNs (IMPLEMENTATION)\n",
    "![RNN](images/bidirectional.png)\n",
    "One restriction of a RNN is that it can't see the future input, only the past.  This is where bidirectional recurrent neural networks come in.  They are able to see the future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (137861, 21, 1)\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, return_sequences=True, input_shape=(21, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 21, 256)           99840     \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 21, 344)           88408     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 188,248\n",
      "Trainable params: 188,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Input shape : (137861, 21, 1)\n",
      "english_vocab_size : 199\n",
      "output_sequence_length : 21\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 21, 256)           99840     \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 21, 344)           88408     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 188,248\n",
      "Trainable params: 188,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 53s - loss: 1.5821 - acc: 0.6047 - val_loss: nan - val_acc: 0.6579\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 51s - loss: 1.0953 - acc: 0.6713 - val_loss: nan - val_acc: 0.6789\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 51s - loss: 0.9736 - acc: 0.6933 - val_loss: nan - val_acc: 0.7023\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 51s - loss: 0.9048 - acc: 0.7047 - val_loss: nan - val_acc: 0.7109\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 51s - loss: 0.8536 - acc: 0.7136 - val_loss: nan - val_acc: 0.7166\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 51s - loss: 0.8162 - acc: 0.7225 - val_loss: nan - val_acc: 0.7340\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 51s - loss: 0.7865 - acc: 0.7319 - val_loss: nan - val_acc: 0.7411\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 52s - loss: 0.7628 - acc: 0.7400 - val_loss: nan - val_acc: 0.7435\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 52s - loss: 0.7421 - acc: 0.7458 - val_loss: nan - val_acc: 0.7580\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 52s - loss: 0.7103 - acc: 0.7601 - val_loss: nan - val_acc: 0.7652\n",
      "new jersey est parfois calme au mois et mai et il est neigeux en <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a bidirectional RNN model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    model = Sequential()\n",
    "    \n",
    "    print(\"Input shape : {}\".format(input_shape))\n",
    "    print(\"english_vocab_size : {}\".format(english_vocab_size))\n",
    "    print(\"output_sequence_length : {}\".format(output_sequence_length))\n",
    "    \n",
    "    model.add(Bidirectional(GRU(units=128,input_dim=1, input_length=output_sequence_length,return_sequences=True)\n",
    "                            ,input_shape=(21, 1)))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate=0.01\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "tests.test_bd_model(bd_model)\n",
    "\n",
    "\n",
    "# TODO: Train and Print prediction(s)\n",
    "\n",
    "# Reshaping the input to work with a basic RNN\n",
    "tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences.shape[-2], 1))\n",
    "\n",
    "# Train the neural network\n",
    "bd_rnn_model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_french_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index),\n",
    "    len(french_tokenizer.word_index))\n",
    "bd_rnn_model.fit(tmp_x, preproc_french_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(bd_rnn_model.predict(tmp_x[:1])[0], french_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Encoder-Decoder (OPTIONAL)\n",
    "Time to look at encoder-decoder models.  This model is made up of an encoder and decoder. The encoder creates a matrix representation of the sentence.  The decoder takes this matrix as input and predicts the translation as output.\n",
    "\n",
    "Create an encoder-decoder model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "\n",
    "\n",
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # OPTIONAL: Implement\n",
    "    return None\n",
    "tests.test_encdec_model(encdec_model)\n",
    "\n",
    "\n",
    "# OPTIONAL: Train and Print prediction(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Custom (IMPLEMENTATION)\n",
    "Use everything you learned from the previous models to create a model that incorporates embedding and a bidirectional rnn into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (137861, 15)\n",
      "english_vocab_size : 199\n",
      "french_vocab_size : 344\n",
      "output_sequence_length : 21\n",
      "model.input_shape : (None, 15)\n",
      "(None, *input_shape[1:]) : (None, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, input_shape=(21, 64))`\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, return_sequences=True, input_shape=(None, 64))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 15, 64)            12736     \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 256)               148224    \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 21, 256)           295680    \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 21, 344)           88408     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 545,048\n",
      "Trainable params: 545,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model.output_shape : (None, 21, 344)\n",
      "(None, output_sequence_length, french_vocab_size) : (None, 21, 344)\n",
      "Final Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train a model that incorporates embedding, encoder-decoder, and bidirectional RNN on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(english_vocab_size, 64, input_length=input_shape[1]))\n",
    "    \n",
    "    print(\"Input shape : {}\".format(input_shape))\n",
    "    print(\"english_vocab_size : {}\".format(english_vocab_size))\n",
    "    print(\"french_vocab_size : {}\".format(french_vocab_size))\n",
    "    print(\"output_sequence_length : {}\".format(output_sequence_length))\n",
    "    \n",
    "    print(\"model.input_shape : {}\".format(model.input_shape))\n",
    "    print(\"(None, *input_shape[1:]) : {}\".format((None, *input_shape[1:])))\n",
    "    \n",
    "    \n",
    "    #model.add(GRU(units=128,input_dim=64, input_length=output_sequence_length,return_sequences=True))\n",
    "    model.add(Bidirectional(GRU(units=128,input_dim=64, input_length=output_sequence_length)\n",
    "                            ))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(units=128,input_dim=64, return_sequences=True)\n",
    "                            ))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(french_vocab_size)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    learning_rate=0.01\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    print(\"model.output_shape : {}\".format(model.output_shape))\n",
    "    print(\"(None, output_sequence_length, french_vocab_size) : {}\"\n",
    "          .format((None, output_sequence_length, french_vocab_size)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model\n",
    "tests.test_model_final(model_final)\n",
    "\n",
    "\n",
    "print('Final Model Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction (IMPLEMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : (137861, 15)\n",
      "english_vocab_size : 199\n",
      "french_vocab_size : 344\n",
      "output_sequence_length : 21\n",
      "model.input_shape : (None, 15)\n",
      "(None, *input_shape[1:]) : (None, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, input_shape=(21, 64))`\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\progs\\anaconda3\\envs\\aind-nlp-capstone\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(units=128, return_sequences=True, input_shape=(None, 64))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 15, 64)            12736     \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 256)               148224    \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 21, 256)           295680    \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 21, 344)           88408     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 344)           0         \n",
      "=================================================================\n",
      "Total params: 545,048\n",
      "Trainable params: 545,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "model.output_shape : (None, 21, 344)\n",
      "(None, output_sequence_length, french_vocab_size) : (None, 21, 344)\n",
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/10\n",
      "110288/110288 [==============================] - 86s - loss: 2.0543 - acc: 0.5272 - val_loss: nan - val_acc: 0.6380\n",
      "Epoch 2/10\n",
      "110288/110288 [==============================] - 80s - loss: 1.0255 - acc: 0.7125 - val_loss: nan - val_acc: 0.7655\n",
      "Epoch 3/10\n",
      "110288/110288 [==============================] - 80s - loss: 0.6306 - acc: 0.8138 - val_loss: nan - val_acc: 0.8189\n",
      "Epoch 4/10\n",
      "110288/110288 [==============================] - 81s - loss: 0.3436 - acc: 0.9038 - val_loss: nan - val_acc: 0.9341\n",
      "Epoch 5/10\n",
      "110288/110288 [==============================] - 81s - loss: 0.2063 - acc: 0.9440 - val_loss: nan - val_acc: 0.9550\n",
      "Epoch 6/10\n",
      "110288/110288 [==============================] - 82s - loss: 0.2134 - acc: 0.9392 - val_loss: nan - val_acc: 0.9442\n",
      "Epoch 7/10\n",
      "110288/110288 [==============================] - 82s - loss: 0.1408 - acc: 0.9598 - val_loss: nan - val_acc: 0.9612\n",
      "Epoch 8/10\n",
      "110288/110288 [==============================] - 83s - loss: 0.1296 - acc: 0.9626 - val_loss: nan - val_acc: 0.9647\n",
      "Epoch 9/10\n",
      "110288/110288 [==============================] - 83s - loss: 0.1293 - acc: 0.9620 - val_loss: nan - val_acc: 0.9611\n",
      "Epoch 10/10\n",
      "110288/110288 [==============================] - 84s - loss: 0.1154 - acc: 0.9665 - val_loss: nan - val_acc: 0.9655\n",
      "Sample 1:\n",
      "at est poires <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Il a vu un vieux camion jaune\n",
      "Sample 2:\n",
      "new jersey est parfois calme pendant l' automne et il est neigeux en avril <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    \"\"\"\n",
    "    Gets predictions using the final model\n",
    "    :param x: Preprocessed English data\n",
    "    :param y: Preprocessed French data\n",
    "    :param x_tk: English tokenizer\n",
    "    :param y_tk: French tokenizer\n",
    "    \"\"\"\n",
    "    # TODO: Train neural network using model_final\n",
    "    #tmp_x = pad(preproc_english_sentences, preproc_french_sentences.shape[1])\n",
    "\n",
    "    model = model_final(\n",
    "    x.shape,\n",
    "    y.shape[1],\n",
    "    len(x_tk.word_index),\n",
    "    len(y_tk.word_index))\n",
    "    model.fit(x, y, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "\n",
    "\n",
    "    \n",
    "    ## DON'T EDIT ANYTHING BELOW THIS LINE\n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "    sentence = 'he saw a old yellow truck'\n",
    "    sentence = 'where are we going'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('Il a vu un vieux camion jaune')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in y[0]]))\n",
    "    return model\n",
    "\n",
    "\n",
    "final_model=final_predictions(preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "il conduit un nouveau camion vert <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
    "y_id_to_word[0] = '<PAD>'\n",
    "\n",
    "\n",
    "sentence = 'he drives a green truck'\n",
    "sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "sentence = pad_sequences([sentence], maxlen=preproc_english_sentences.shape[-1], padding='post')\n",
    "sentences = np.array([sentence[0]])\n",
    "predictions = final_model.predict(sentences, len(sentences))\n",
    "\n",
    "print('Sample 1:')\n",
    "print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit your project, do the following steps:\n",
    "1. Ensure you pass all points on the [rubric](https://review.udacity.com/#!/rubrics/1004/view).\n",
    "2. Submit the following in a zip file.\n",
    "  - `helper.py`\n",
    "  - `machine_translation.ipynb`\n",
    "  - `machine_translation.html`\n",
    "    - You can export the notebook by navigating to **File -> Download as -> HTML (.html)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
